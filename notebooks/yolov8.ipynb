{
 'cells': [
  {
   'cell_type': 'markdown',
   'id': '9f24766c-af59-4ae6-a00b-39051ef783a9',
   'metadata': {
    'id': '9f24766c-af59-4ae6-a00b-39051ef783a9'
   },
   'source': [
    '## Install and Import Package\n',
    'Installing the **ultralytics** library\n',
    '**Ultralytics** is a library that provides tools for working with the YOLOv8 model. YOLOv8 is an advanced model for object detection, image segmentation, and image classification'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': '1c6fe336-9564-4d40-bbc4-ae9a823ea6e4',
   'metadata': {
    'colab': {
     'base_uri': 'https://localhost:8080/',
     'height': 1000
    },
    'id': '1c6fe336-9564-4d40-bbc4-ae9a823ea6e4',
    'outputId': '771faace-b2e3-4f2e-c09f-42a36dfbabec',
    'scrolled': true,
    'tags': []
   },
   'outputs': [],
   'source': [
    '!pip install ultralytics'
   ]
  },
  {
   'cell_type': 'markdown',
   'source': [
    'Downloading the Required Libraries\n'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': '4ed7c87fd8b2bc91'
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'outputs': [],
   'source': [
    'import zipfile\n',
    'import requests\n',
    'import cv2\n',
    'import matplotlib.pyplot as plt\n',
    'import glob \n',
    'import random\n',
    'import os'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': '5f2f4483-81e9-4378-8e98-222ed56e0bad'
  },
  {
   'cell_type': 'markdown',
   'source': [
    '## Clone Git Repo\n',
    'Copying data from a repository GitHub'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': 'eecf81d1cc44aa6c'
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'outputs': [],
   'source': [
    '!git clone https://github.com/ThatCoderMan/Hay_test_task.git\n',
    '!cp -rf ./Hay_test_task/* ./\n',
    '!rm -r Hay_test_task/'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': 'a142418b02cab44e'
  },
  {
   'cell_type': 'markdown',
   'id': 'aca11f1c-3328-429d-949b-a942d011b328',
   'metadata': {
    'id': 'aca11f1c-3328-429d-949b-a942d011b328'
   },
   'source': [
    '## Download the Dataset\n',
    'Downloading prepared masks from the site [roboflow](https://app.roboflow.com/ds)'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'outputs': [],
   'source': [
    'os.makedirs('datasets', exist_ok=True)\n',
    '%cd datasets\n',
    '!curl -L \'https://app.roboflow.com/ds/mzocbskx4m?key=Eb2lIuRA0D\' > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n',
    '%cd ..'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': '43ed3ece-3bc5-41f4-bdf8-0e715051be0a'
  },
  {
   'cell_type': 'markdown',
   'source': [
    'Downloading the original video from Google drive'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': '2b9e3e0900f563e6'
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'outputs': [],
   'source': [
    '%cd data/videos\n',
    '!wget --no-check-certificate 'https://drive.usercontent.google.com/download?id=1_lWgETFS_sxk9tzgtteI5PZEeGzTdIXq&export=download&authuser=0&confirm=t&uuid=734bc640-a87a-48f7-b451-3d7d7946b78d&at=APZUnTW9SicfuV7bc74bHdfxhNjp:1698261775232' -O video.mp4\n',
    '%cd ../..\n',
    '%pwd'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': '5f45816a2c8e71a1'
  },
  {
   'cell_type': 'markdown',
   'id': '67106dfe-ce91-48d1-ac7b-d40093ca040b',
   'metadata': {
    'id': '67106dfe-ce91-48d1-ac7b-d40093ca040b'
   },
   'source': [
    '## Visualize Images from the Dataset\n',
    'Checking formats on prepared data'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': 'ef2f34fc-564c-4cfd-928a-33fd6cacaf59',
   'metadata': {
    'id': 'ef2f34fc-564c-4cfd-928a-33fd6cacaf59'
   },
   'outputs': [],
   'source': [
    '# Function to convert bounding boxes in YOLO format to xmin, ymin, xmax, ymax.\n',
    'def yolo2bbox(bboxes):\n',
    '    xmin, ymin = bboxes[0]-bboxes[2]/2, bboxes[1]-bboxes[3]/2\n',
    '    xmax, ymax = bboxes[0]+bboxes[2]/2, bboxes[1]+bboxes[3]/2\n',
    '    return xmin, ymin, xmax, ymax'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': '5a213ff6-fb28-4541-80f4-0f8c67323d9b',
   'metadata': {
    'id': '5a213ff6-fb28-4541-80f4-0f8c67323d9b'
   },
   'outputs': [],
   'source': [
    'def plot_box(image, bboxes, labels):\n',
    '    # Need the image height and width to denormalize\n',
    '    # the bounding box coordinates\n',
    '    h, w, _ = image.shape\n',
    '    for box_num, box in enumerate(bboxes):\n',
    '        x1, y1, x2, y2 = yolo2bbox(box)\n',
    '        # Denormalize the coordinates.\n',
    '        xmin = int(x1*w)\n',
    '        ymin = int(y1*h)\n',
    '        xmax = int(x2*w)\n',
    '        ymax = int(y2*h)\n',
    '\n',
    '        thickness = max(2, int(w/275))\n',
    '                \n',
    '        cv2.rectangle(\n',
    '            image, \n',
    '            (xmin, ymin), (xmax, ymax),\n',
    '            color=(0, 0, 255),\n',
    '            thickness=thickness\n',
    '        )\n',
    '    return image'
   ]
  },
  {
   'cell_type': 'markdown',
   'source': [
    '# Function to plot images with the bounding boxes.'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': 'a081d26aecdcfdc5'
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': '17582d3e-2f08-430b-ab70-abced31cbe3c',
   'metadata': {
    'id': '17582d3e-2f08-430b-ab70-abced31cbe3c'
   },
   'outputs': [],
   'source': [
    '\n',
    'def plot(image_paths, label_paths, num_samples):\n',
    '    all_images = []\n',
    '    all_images.extend(glob.glob(image_paths+'/*.jpg'))\n',
    '    all_images.extend(glob.glob(image_paths+'/*.JPG'))\n',
    '    \n',
    '    all_images.sort()\n',
    '\n',
    '    num_images = len(all_images)\n',
    '    \n',
    '    plt.figure(figsize=(15, 12))\n',
    '    for i in range(num_samples):\n',
    '        j = random.randint(0,num_images-1)\n',
    '        image_name = all_images[j]\n',
    '        image_name = '.'.join(image_name.split(os.path.sep)[-1].split('.')[:-1])\n',
    '        image = cv2.imread(all_images[j])\n',
    '        with open(os.path.join(label_paths, image_name+'.txt'), 'r') as f:\n',
    '            bboxes = []\n',
    '            labels = []\n',
    '            label_lines = f.readlines()\n',
    '            for label_line in label_lines:\n',
    '                label = label_line[0]\n',
    '                bbox_string = label_line[2:]\n',
    '                x_c, y_c, w, h = bbox_string.split(' ')\n',
    '                x_c = float(x_c)\n',
    '                y_c = float(y_c)\n',
    '                w = float(w)\n',
    '                h = float(h)\n',
    '                bboxes.append([x_c, y_c, w, h])\n',
    '                labels.append(label)\n',
    '        result_image = plot_box(image, bboxes, labels)\n',
    '        plt.subplot(2, 2, i+1)\n',
    '        plt.imshow(result_image[:, :, ::-1])\n',
    '        plt.axis('off')\n',
    '    plt.subplots_adjust(wspace=1)\n',
    '    plt.tight_layout()\n',
    '    plt.show()'
   ]
  },
  {
   'cell_type': 'markdown',
   'source': [
    '# Visualize a few training images.'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': 'ed31430ce088c800'
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': '29598f69-a9a2-4e3f-bcd4-18255a9d7f19',
   'metadata': {
    'colab': {
     'base_uri': 'https://localhost:8080/',
     'height': 793
    },
    'id': '29598f69-a9a2-4e3f-bcd4-18255a9d7f19',
    'outputId': '2c897ab8-33ab-45fd-aff9-72718ce4bd6a'
   },
   'outputs': [],
   'source': [
    '\n',
    'plot(\n',
    '    image_paths='datasets/train/images/', \n',
    '    label_paths='datasets/train/labels/',\n',
    '    num_samples=4,\n',
    ')'
   ]
  },
  {
   'cell_type': 'markdown',
   'id': 'c25ceb15-6d00-4afa-a349-4dd4fdcf5193',
   'metadata': {
    'id': 'c25ceb15-6d00-4afa-a349-4dd4fdcf5193'
   },
   'source': [
    '## Dataset YAML File\n',
    'Creating a File YAML for _Training_ and _Validation_ Files'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': 'b0031a4a-b114-444f-bc9e-e5e30ac79e42',
   'metadata': {
    'colab': {
     'base_uri': 'https://localhost:8080/'
    },
    'id': 'b0031a4a-b114-444f-bc9e-e5e30ac79e42',
    'outputId': 'c748a3cf-528e-49d5-e0b3-3ef9d1d78b4e'
   },
   'outputs': [],
   'source': [
    '%%writefile hay.yaml\n',
    'path: ''\n',
    'train: 'train/images'\n',
    'val: 'valid/images'\n',
    '\n',
    'names: \n',
    '  0: 'hay''
   ]
  },
  {
   'cell_type': 'markdown',
   'id': '9e86ee50-a8f0-4500-a001-42fb3f18439d',
   'metadata': {
    'id': '9e86ee50-a8f0-4500-a001-42fb3f18439d'
   },
   'source': [
    '## YOLOv8 Large Training'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': '81a6b664-8e6f-4e31-ba6b-304164c40e1a',
   'metadata': {
    'colab': {
     'base_uri': 'https://localhost:8080/'
    },
    'id': '81a6b664-8e6f-4e31-ba6b-304164c40e1a',
    'outputId': 'ec52898e-3ae0-4889-97d2-0ba36223ecaf',
    'scrolled': true,
    'tags': []
   },
   'outputs': [],
   'source': [
    'EPOCHS = 100\n',
    '!yolo task=detect mode=train model=yolov8l.pt epochs={EPOCHS} batch=8 name=hay_model data=hay.yaml'
   ]
  },
  {
   'cell_type': 'markdown',
   'id': '03071a7c-6c2b-45e0-8a9c-f37384fab77e',
   'metadata': {
    'id': '03071a7c-6c2b-45e0-8a9c-f37384fab77e'
   },
   'source': [
    '## Inference on Validation Images\n',
    'Video-to-video tracking command'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'outputs': [],
   'source': [
    '# !yolo track \\\n',
    '# model=runs/detect/hay_model/weights/best.pt \\\n',
    '# source=data/videos/Seno1.mp4 \\\n',
    '# name=result \\\n',
    '# hide_labels=True \\\n',
    '# conf=0.1 iou=0.75'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': 'bfd164748b0eace2'
  },
  {
   'cell_type': 'markdown',
   'source': [
    'Command to localize objects from photo to photo'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': '6a495726d764b69e'
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'outputs': [],
   'source': [
    '!yolo task=detect \\\n',
    'mode=predict \\\n',
    'model=runs/detect/hay_model/weights/best.pt \\\n',
    'source=data/videos/original_video \\\n',
    'name=result \\\n',
    'hide_labels=True'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': 'b2e2073a-d46e-47f4-8b82-de3d424ef633'
  },
  {
   'cell_type': 'markdown',
   'source': [
    'Convert Photos to Videos'
   ],
   'metadata': {
    'collapsed': false
   },
   'id': '327fe6242ff2e49f'
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'outputs': [],
   'source': [
    '# !ffmpeg -f image2 -r 24 -i ./runs/detect/result/frame_%04d.jpg  result.mp4 '
   ],
   'metadata': {
    'collapsed': false
   },
   'id': '89d22fd3674ce1e4'
  },
  {
   'cell_type': 'markdown',
   'id': '53b20328-2e16-4ef0-855c-5212b058e539',
   'metadata': {
    'id': '53b20328-2e16-4ef0-855c-5212b058e539'
   },
   'source': [
    '## Visualize Validation Results\n',
    'Display of processed data'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': '06dcd014-8a95-424e-b443-0ae3bd404431',
   'metadata': {
    'id': '06dcd014-8a95-424e-b443-0ae3bd404431'
   },
   'outputs': [],
   'source': [
    '# Plot and visualize images in a 2x2 grid.\n',
    'def visualize(result_dir, num_samples=4):\n',
    '    \'\'\'\n',
    '    Function accepts a list of images and plots\n',
    '    them in a 2x2 grid.\n',
    '    \'\'\'\n',
    '    plt.figure(figsize=(20, 12))\n',
    '    image_names = glob.glob(os.path.join(result_dir, '*.jpg'))\n',
    '    random.shuffle(image_names)\n',
    '    for i, image_name in enumerate(image_names):\n',
    '        image = plt.imread(image_name)\n',
    '        plt.subplot(2, 2, i+1)\n',
    '        plt.imshow(image)\n',
    '        plt.axis('off')\n',
    '        if i == num_samples-1:\n',
    '            break\n',
    '    plt.tight_layout()\n',
    '    plt.show()'
   ]
  },
  {
   'cell_type': 'code',
   'execution_count': null,
   'id': 'd2b3f113-cc15-4a46-906a-9884ca3780d1',
   'metadata': {
    'id': 'd2b3f113-cc15-4a46-906a-9884ca3780d1'
   },
   'outputs': [],
   'source': [
    'visualize('runs/detect/result/')'
   ]
  }
 ],
 'metadata': {
  'accelerator': 'GPU',
  'colab': {
   'provenance': []
  },
  'gpuClass': 'standard',
  'kernelspec': {
   'display_name': 'Python 3',
   'language': 'python',
   'name': 'python3'
  },
  'language_info': {
   'codemirror_mode': {
    'name': 'ipython',
    'version': 3
   },
   'file_extension': '.py',
   'mimetype': 'text/x-python',
   'name': 'python',
   'nbconvert_exporter': 'python',
   'pygments_lexer': 'ipython3',
   'version': '3.9.15'
  }
 },
 'nbformat': 4,
 'nbformat_minor': 5
}
